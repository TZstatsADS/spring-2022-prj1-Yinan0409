seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
return(ldaOut)
}
output_topic <- function(ldaOut, filecode){
#write out results
#docs to topics
ldaOut.topics <- as.matrix(topics(ldaOut))
table(c(1:k, ldaOut.topics))
write.csv(ldaOut.topics,file=paste("../output/LDAGibbs", filecode, k,"DocsToTopics.csv"))
#top 10 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
write.csv(ldaOut.terms,file=paste("../output/LDAGibbs", filecode, k, "TopicsToTerms.csv"))
#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("../output/LDAGibbs", filecode, k,"TopicProbabilities.csv"))
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms
}
dtm.mat.man <- generate_dtm(sentense.all, "aristotle", "man|men|people")
#write get_topic function
generate_dtm <- function(dataset, sch, keyword, filecode){
sentense <- dataset %>% filter (school==sch)
sentense <- sentense %>% filter (grepl(keyword, sentence_lowered))
write.csv(sentense,file=paste("../output/Speech",filecode,".csv"))
corpus <- VCorpus(VectorSource(sentense$sentence_lowered))
corpus<-tm_map(corpus, stripWhitespace)
corpus<-tm_map(corpus, content_transformer(tolower))
corpus<-tm_map(corpus, removeWords, stopwords("english"))
corpus<-tm_map(corpus, removeWords, useless_words)
corpus<-tm_map(corpus, removePunctuation)
dtm <- DocumentTermMatrix(corpus)
return(dtm)
}
get_topic <- function(dtm, k){
#Set parameters
burnin <- 4000
iter <- 1000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
#Run LDA using Gibbs sampling
ldaOut <-LDA(dtm, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
return(ldaOut)
}
output_topic <- function(ldaOut, filecode){
#write out results
#docs to topics
ldaOut.topics <- as.matrix(topics(ldaOut))
table(c(1:k, ldaOut.topics))
write.csv(ldaOut.topics,file=paste("../output/LDAGibbs", filecode, k,"DocsToTopics.csv"))
#top 10 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
write.csv(ldaOut.terms,file=paste("../output/LDAGibbs", filecode, k, "TopicsToTerms.csv"))
#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("../output/LDAGibbs", filecode, k,"TopicProbabilities.csv"))
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms
}
dtm.mat.man <- generate_dtm(sentense.all, "aristotle", "man|men|people","mat.man")
ldaOut.mat.man <-LDA(dtm.mat.man, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.mat.man,"mat_man")
dtm.mat.man <- generate_dtm(sentense.all, "aristotle", "man|men|people|person","mat.man")
ldaOut.mat.man <-LDA(dtm.mat.man, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.mat.man,"mat_man")
dtm.mat.man <- generate_dtm(sentense.all, "aristotle", "man|men","mat.man")
ldaOut.mat.man <-LDA(dtm.mat.man, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.mat.man,"mat_man")
dtm.idea.man <- generate_dtm(sentense.all, idea_schools, "man|men","idea.man")
ldaOut.idea.man <-LDA(dtm.idea.man, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.idea.man,"idea_man")
dtm.mat.thing <- generate_dtm(sentense.all, "aristotle", "thing|things","mat.thing")
ldaOut.mat.thing <-LDA(dtm.mat.thing, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
ldaOut.mat.thing <-LDA(dtm.mat.thing, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
#write get_topic function
generate_dtm <- function(dataset, sch, keyword, filecode){
sentense <- dataset %>% filter (school==sch)
sentense <- sentense %>% filter (grepl(keyword, sentence_lowered))
write.csv(sentense,file=paste("../output/Speech",filecode,".csv"))
corpus <- VCorpus(VectorSource(sentense$sentence_lowered))
corpus<-tm_map(corpus, stripWhitespace)
corpus<-tm_map(corpus, content_transformer(tolower))
corpus<-tm_map(corpus, removeWords, stopwords("english"))
corpus<-tm_map(corpus, removeWords, useless_words)
corpus<-tm_map(corpus, removePunctuation)
dtm <- DocumentTermMatrix(corpus)
rowTotals <- apply(dtm, 1, sum) #Find the sum of words in each Document
dtm  <- dtm[rowTotals> 0, ]
return(dtm)
}
get_topic <- function(dtm, k){
#Set parameters
burnin <- 4000
iter <- 1000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
#Run LDA using Gibbs sampling
ldaOut <-LDA(dtm, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
return(ldaOut)
}
output_topic <- function(ldaOut, filecode){
#write out results
#docs to topics
ldaOut.topics <- as.matrix(topics(ldaOut))
table(c(1:k, ldaOut.topics))
write.csv(ldaOut.topics,file=paste("../output/LDAGibbs", filecode, k,"DocsToTopics.csv"))
#top 10 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
write.csv(ldaOut.terms,file=paste("../output/LDAGibbs", filecode, k, "TopicsToTerms.csv"))
#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("../output/LDAGibbs", filecode, k,"TopicProbabilities.csv"))
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms
}
dtm.mat.man <- generate_dtm(sentense.all, "aristotle", "man|men","mat.man")
ldaOut.mat.man <-LDA(dtm.mat.man, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.mat.man,"mat_man")
dtm.mat.thing <- generate_dtm(sentense.all, "aristotle", "thing|things","mat.thing")
ldaOut.mat.thing <-LDA(dtm.mat.thing, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.mat.thing,"mat_thing")
dtm.idea.thing <- generate_dtm(sentense.all, idea_schools, "thing|things","idea.thing")
ldaOut.idea.thing <-LDA(dtm.idea.thing, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.idea.thing,"idea_thing")
dtm.idea.thing <- generate_dtm(speech.all, idea_schools, "thing|things","idea.thing")
ldaOut.idea.thing <-LDA(dtm.idea.thing, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.idea.thing,"idea_thing")
dtm.mat.thing <- generate_dtm(speech.all, "aristotle", "thing|things","mat.thing")
ldaOut.mat.thing <-LDA(dtm.mat.thing, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.mat.thing,"mat_thing")
set.seed(0)
dtm.mat.man <- generate_dtm(sentense.all, "aristotle", "man|men","mat.man")
ldaOut.mat.man <-LDA(dtm.mat.man, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
dtm.mat.man <- generate_dtm(speech.all, "aristotle", "man|men","mat.man")
set.seed(0)
ldaOut.mat.man <-LDA(dtm.mat.man, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
output_topic(ldaOut.mat.man,"mat_man")
rm(list=ls())
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels","readtext","worldcloud","tydytext","RColorBrewer")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("readtext")
library("RColorBrewer")
library("wordcloud")
library("tidytext")
print(R.version)
dataset1 <- read.csv("../data/philosophy_data.csv")
dataset2 <- read.csv("../data/philosophy_data.csv",encoding = "UTF-8")
speech.all <- dataset1 %>% select (school,author,title,sentence_lowered)
speech.mat <- speech.all %>% filter (school == "aristotle")
idea_schools <- c("german_idealism","plato")
speech.idea <- speech.all %>% filter (school == idea_schools)
dataset1 <- read.csv("../data/philosophy_data.csv")
rm(list=ls())
speech.all <- dataset1 %>% select (school,author,title,sentence_lowered)
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels","readtext","worldcloud","tydytext","RColorBrewer")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("readtext")
library("RColorBrewer")
library("wordcloud")
library("tidytext")
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels","readtext","worldcloud","tydytext","RColorBrewer")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("readtext")
library("RColorBrewer")
library("wordcloud")
library("tidytext")
print(R.version)
dataset1 <- read.csv("../data/philosophy_data.csv")
speech.all <- dataset1 %>% select (school,author,title,sentence_lowered)
speech.mat <- speech.all %>% filter (school == "aristotle")
idea_schools <- c("german_idealism","plato")
speech.idea <- speech.all %>% filter (school == idea_schools)
useless_words <- c("one", "will", "also", "just","can","called","therefore","something")
#Build Corpus of Materialism
corpus.mat<-VCorpus(VectorSource(speech.mat$sentence_lowered))
corpus.mat<-tm_map(corpus.mat, stripWhitespace)
corpus.mat<-tm_map(corpus.mat, content_transformer(tolower))
corpus.mat<-tm_map(corpus.mat, removeWords, stopwords("english"))
corpus.mat<-tm_map(corpus.mat, removeWords, useless_words)
corpus.mat<-tm_map(corpus.mat, removePunctuation)
tdm.mat<-TermDocumentMatrix(corpus.mat)
tdm.tidy.mat=tidy(tdm.mat)
tdm.overall.mat=summarise(group_by(tdm.tidy.mat, term), sum(count))
wordcloud(tdm.overall.mat$term, tdm.overall.mat$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
#Build Corpus of Idealism
corpus.idea<-VCorpus(VectorSource(speech.idea$sentence_lowered))
corpus.idea<-tm_map(corpus.idea, stripWhitespace)
corpus.idea<-tm_map(corpus.idea, content_transformer(tolower))
corpus.idea<-tm_map(corpus.idea, removeWords, stopwords("english"))
corpus.idea<-tm_map(corpus.idea, removeWords, useless_words)
corpus.idea<-tm_map(corpus.idea, removePunctuation)
tdm.idea<-TermDocumentMatrix(corpus.idea)
tdm.tidy.idea=tidy(tdm.idea)
tdm.overall.idea=summarise(group_by(tdm.tidy.idea, term), sum(count))
wordcloud(tdm.overall.idea$term, tdm.overall.idea$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Reds"))
#write get_topic function
generate_dtm <- function(dataset, sch, keyword, filecode){
sentence <- dataset %>% filter (school==sch)
sentence <- sentence %>% filter (grepl(keyword, sentence_lowered))
write.csv(sentence,file=paste("../output/Speech",filecode,".csv"))
corpus <- VCorpus(VectorSource(sentence$sentence_lowered))
corpus<-tm_map(corpus, stripWhitespace)
corpus<-tm_map(corpus, content_transformer(tolower))
corpus<-tm_map(corpus, removeWords, stopwords("english"))
corpus<-tm_map(corpus, removeWords, useless_words)
corpus<-tm_map(corpus, removePunctuation)
dtm <- DocumentTermMatrix(corpus)
rowTotals <- apply(dtm, 1, sum) #Find the sum of words in each Document
dtm  <- dtm[rowTotals> 0, ]
return(dtm)
}
get_topic <- function(dtm, k){
#Set parameters
burnin <- 4000
iter <- 1000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
#Run LDA using Gibbs sampling
ldaOut <-LDA(dtm, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
return(ldaOut)
}
output_topic <- function(ldaOut, filecode){
#write out results
#docs to topics
ldaOut.topics <- as.matrix(topics(ldaOut))
table(c(1:k, ldaOut.topics))
write.csv(ldaOut.topics,file=paste("../output/LDAGibbs", filecode, k,"DocsToTopics.csv"))
#top 10 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
write.csv(ldaOut.terms,file=paste("../output/LDAGibbs", filecode, k, "TopicsToTerms.csv"))
#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("../output/LDAGibbs", filecode, k,"TopicProbabilities.csv"))
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms
}
dtm.mat.man <- generate_dtm(speech.all, "aristotle", "man|men","mat.man")
set.seed(20)
ldaOut.mat.man <-LDA(dtm.mat.man, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
dtm.mat.man <- generate_dtm(speech.all, "aristotle", "man|men","mat.man")
dtm.mat.man <- generate_dtm(speech.all, "aristotle", "man|men","mat.man")
set.seed(20)
ldaOut.mat.man <-get_topic(dtm.mat.man,5)
output_topic(ldaOut.mat.man,"mat_man")
output_topic(ldaOut.mat.man,"mat_man",5)
output_topic <- function(ldaOut, filecode,k){
#write out results
#docs to topics
ldaOut.topics <- as.matrix(topics(ldaOut))
table(c(1:k, ldaOut.topics))
write.csv(ldaOut.topics,file=paste("../output/LDAGibbs", filecode,"DocsToTopics.csv"))
#top 10 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
write.csv(ldaOut.terms,file=paste("../output/LDAGibbs", filecode, "TopicsToTerms.csv"))
#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("../output/LDAGibbs", filecode,"TopicProbabilities.csv"))
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms
}
output_topic(ldaOut.mat.man,"mat_man",5)
dtm.idea.man <- generate_dtm(speech.all, idea_schools, "man|men","idea.man")
dtm.idea.man <- generate_dtm(speech.all, idea_schools, "man|men|people","idea.man")
set.seed(20)
ldaOut.idea.man <-get_topic(dtm.idea.man,5)
output_topic(ldaOut.idea.man,"idea_man",5)
dtm.mat.thing <- generate_dtm(speech.all, "aristotle", "thing|things","mat.thing")
set.seed(20)
ldaOut.mat.thing <-get_topic(dtm.mat.thing,5)
output_topic(ldaOut.mat.thing,"mat_thing",5)
dtm.idea.thing <- generate_dtm(speech.all, idea_schools, "thing|things","idea.thing")
set.seed(20)
ldaOut.idea.thing <-get_topic(dtm.idea.thing,5)
output_topic(ldaOut.idea.thing,"idea_thing")
dtm.idea.thing <- generate_dtm(speech.all, idea_schools, "thing|things","idea.thing")
set.seed(20)
ldaOut.idea.thing <-get_topic(dtm.idea.thing,5)
output_topic(ldaOut.idea.thing,"idea_thing",5)
dtm.idea.thing <- generate_dtm(speech.all, idea_schools, "thing|things","idea.thing")
set.seed(0)
ldaOut.idea.thing <-get_topic(dtm.idea.thing,5)
output_topic(ldaOut.idea.thing,"idea_thing",5)
dtm.idea.thing <- generate_dtm(speech.all, idea_schools, "thing|things","idea.thing")
set.seed(20)
ldaOut.idea.thing <-get_topic(dtm.idea.thing,5)
output_topic(ldaOut.idea.thing,"idea_thing",5)
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels","readtext","worldcloud","tydytext","RColorBrewer")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("readtext")
library("RColorBrewer")
library("wordcloud")
library("tidytext")
